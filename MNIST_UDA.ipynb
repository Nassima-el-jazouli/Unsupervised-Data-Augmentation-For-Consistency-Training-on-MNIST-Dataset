{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "USSV_OlCFKOD"
      },
      "source": [
        "# Laod data and prepare it\n",
        "This simple example demonstrates how to plug TensorFlow Datasets (TFDS) into a Keras model.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TTBSvHcSLBzc"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "import tensorflow_datasets as tfds\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from tensorflow import keras\n",
        "import math\n",
        "import time\n",
        "from tqdm import trange"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZUMhCXhFXdHQ",
        "outputId": "f59a9f3f-0c2b-4d45-9fde-edcc43a9624d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training dataset: 60000\n",
            "test dataset: 10000\n"
          ]
        }
      ],
      "source": [
        "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.mnist.load_data()\n",
        "\n",
        "# Rescale the images from [0,255] to the [0.0,1.0] range.\n",
        "x_train, x_test = x_train[..., np.newaxis]/255.0, x_test[..., np.newaxis]/255.0\n",
        "\n",
        "print(\"training dataset:\", len(x_train))\n",
        "print(\"test dataset:\", len(x_test))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 470
        },
        "id": "n_Ws7js48FGI",
        "outputId": "75f560ab-5aa8-4b65-8952-bbe8c4b48079"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.colorbar.Colorbar at 0x7a6754c5bc40>"
            ]
          },
          "metadata": {},
          "execution_count": 4
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "print(y_train[0])\n",
        "\n",
        "plt.imshow(x_train[0, :, :, 0])\n",
        "plt.colorbar()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1rhSpKtEuD6C",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2bb5ea17-abf4-4060-fab0-cfac0ff5f4af"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-5-a394babc2174>:2: DeprecationWarning: Please use `shift` from the `scipy.ndimage` namespace, the `scipy.ndimage.interpolation` namespace is deprecated.\n",
            "  from scipy.ndimage.interpolation import shift\n"
          ]
        }
      ],
      "source": [
        "# Importation de la fonction shift du module scipy.ndimage.interpolation\n",
        "from scipy.ndimage.interpolation import shift\n",
        "\n",
        "# Définition d'une méthode pour déplacer une image selon les dimensions spécifiées\n",
        "def shift_image(image, dx, dy):\n",
        "    # Remodelage de l'image en une matrice de dimensions 28x28\n",
        "    image = image.reshape((28, 28))\n",
        "\n",
        "    # Appel de la fonction shift pour déplacer l'image selon les paramètres dx et dy\n",
        "    # cval spécifie la valeur à utiliser pour remplir les zones nouvellement créées\n",
        "    # mode spécifie le mode de remplissage pour les zones nouvellement créées (constant dans ce cas)\n",
        "    shifted_image = shift(image, [dy, dx], cval=0, mode=\"constant\")\n",
        "\n",
        "    # Retourne l'image déplacée\n",
        "    return shifted_image\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "18xqJkKTUAh0"
      },
      "outputs": [],
      "source": [
        "# Importation du module NumPy\n",
        "import numpy as np\n",
        "\n",
        "# Création d'un tableau de 100 éléments, initialisés à 1\n",
        "idxs = np.ones(100)\n",
        "\n",
        "# Boucle parcourant les chiffres de 0 à 9\n",
        "for digit in range(10):\n",
        "    # Trouver les indices des occurrences du chiffre dans y_train\n",
        "    digit_args = np.argwhere(y_train == digit)[:10, 0]\n",
        "\n",
        "    # Mélanger aléatoirement les indices obtenus\n",
        "    np.random.shuffle(digit_args)\n",
        "\n",
        "    # Assigner les indices mélangés aux emplacements appropriés dans idxs\n",
        "    idxs[digit * 10:(digit + 1) * 10] = digit_args\n",
        "\n",
        "# Mélanger aléatoirement l'ensemble des indices dans idxs\n",
        "np.random.shuffle(idxs)\n",
        "\n",
        "# Convertir idxs en une liste d'entiers\n",
        "idxs = list(idxs.astype(\"int\"))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "i7nS0QkEvoML"
      },
      "outputs": [],
      "source": [
        "# Sélection des données d'entraînement étiquetées en utilisant les indices mélangés\n",
        "x_train_labeled = x_train[idxs]\n",
        "y_train_labeled = y_train[idxs]\n",
        "\n",
        "# Suppression des données d'entraînement étiquetées des données d'entraînement originales\n",
        "x_train_unlabeled_original = np.delete(x_train.copy(), idxs, axis=0)\n",
        "\n",
        "# Sélection de la moitié des données d'entraînement non étiquetées originales\n",
        "x_train_unlabeled = x_train_unlabeled_original[:int(x_train_unlabeled_original.shape[0] / 2)]\n",
        "\n",
        "# Création d'un jeu de données augmenté en appliquant une translation aux images non étiquetées sélectionnées\n",
        "x_train_augmented = []\n",
        "for image in x_train_unlabeled:\n",
        "    # Ajout de la version déplacée de l'image à la liste augmentée\n",
        "    x_train_augmented.append(np.expand_dims(shift_image(image, 3, 3), axis=-1))\n",
        "\n",
        "# Conversion de la liste augmentée en un tableau NumPy\n",
        "x_train_augmented = np.array(x_train_augmented)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SwtyPq4_0De9"
      },
      "source": [
        "## Seperate the unlabeled images into original and augmeneted images"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YKigGgCD7z-_"
      },
      "outputs": [],
      "source": [
        "# Initialisation d'un dictionnaire pour stocker les indices associés à chaque chiffre\n",
        "digit_idxs = {}\n",
        "\n",
        "# Boucle parcourant les chiffres de 0 à 9\n",
        "for digit in range(10):\n",
        "    # Trouver les indices des occurrences du chiffre dans y_train\n",
        "    digit_args = np.argwhere(y_train == digit)[:, 0]\n",
        "\n",
        "    # Mélanger aléatoirement les indices obtenus\n",
        "    np.random.shuffle(digit_args)\n",
        "\n",
        "    # Stocker les indices mélangés dans le dictionnaire digit_idxs\n",
        "    digit_idxs[digit] = list(digit_args.astype('int'))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AiCgcetk8fIT",
        "outputId": "b60612c2-82d8-4a5a-c165-f1713278e5de"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2710"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ],
      "source": [
        "# Calcul du nombre minimal d'éléments par classe, en prenant la moitié du nombre minimum d'indices parmi toutes les classes\n",
        "elt_per_class = int(min([len(idxs) for idxs in digit_idxs.values()]) / 2)\n",
        "\n",
        "# Affichage du nombre d'éléments par classe\n",
        "elt_per_class"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9qT0_vqG9gqV"
      },
      "outputs": [],
      "source": [
        "# Initialisation de deux dictionnaires pour stocker les données et les étiquettes associées à chaque chiffre\n",
        "digit_data = {}\n",
        "digit_label = {}\n",
        "\n",
        "# Boucle parcourant les chiffres uniques dans y_train\n",
        "for digit in np.unique(y_train):\n",
        "    # Séparation des indices pour obtenir deux groupes d'indices par classe\n",
        "    indices_1 = digit_idxs[digit][:elt_per_class]\n",
        "    indices_2 = digit_idxs[digit][elt_per_class:elt_per_class * 2]\n",
        "\n",
        "    # Stockage des données associées à chaque chiffre dans digit_data\n",
        "    digit_data[digit] = (x_train[indices_1], x_train[indices_2])\n",
        "\n",
        "    # Stockage des étiquettes associées à chaque chiffre dans digit_label\n",
        "    digit_label[digit] = (y_train[indices_1], y_train[indices_2])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZaWtgfQZ_E5M"
      },
      "outputs": [],
      "source": [
        "# Initialisation des variables original_data et original_labels\n",
        "original_data = None\n",
        "original_labels = None\n",
        "\n",
        "# Boucle parcourant les chiffres uniques dans y_train\n",
        "for digit in np.unique(y_train):\n",
        "    # Si c'est la première itération, assigner les données et les étiquettes correspondantes\n",
        "    if original_data is None:\n",
        "        original_data = digit_data[digit][0]\n",
        "        original_labels = digit_label[digit][0]\n",
        "    else:\n",
        "        # Pour les itérations suivantes, concaténer les données et les étiquettes aux valeurs existantes\n",
        "        original_data = np.concatenate((original_data, digit_data[digit][0]))\n",
        "        original_labels = np.concatenate((original_labels, digit_label[digit][0]))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nR0cJDbnAxs_"
      },
      "outputs": [],
      "source": [
        "# Initialisation des variables augmented_data et augmented_labels\n",
        "augmented_data = None\n",
        "augmented_labels = None\n",
        "\n",
        "# Boucle parcourant les chiffres uniques dans y_train\n",
        "for digit in np.unique(y_train):\n",
        "    # Si c'est la première itération, assigner les données augmentées et les étiquettes correspondantes\n",
        "    if augmented_data is None:\n",
        "        augmented_data = digit_data[digit][1]\n",
        "        augmented_labels = digit_label[digit][1]\n",
        "    else:\n",
        "        # Pour les itérations suivantes, concaténer les données augmentées et les étiquettes aux valeurs existantes\n",
        "        augmented_data = np.concatenate((augmented_data, digit_data[digit][1]))\n",
        "        augmented_labels = np.concatenate((augmented_labels, digit_label[digit][1]))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YDvlNdtuBvkn"
      },
      "outputs": [],
      "source": [
        "# Génération d'une permutation aléatoire des indices pour réorganiser les données\n",
        "permutation = np.random.permutation(original_data.shape[0])\n",
        "\n",
        "# Application de la permutation aux données et étiquettes originales et augmentées\n",
        "augmented_data, original_data, augmented_labels, original_labels = augmented_data[permutation], \\\n",
        "original_data[permutation], augmented_labels[permutation], original_labels[permutation]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "niiyeDsDA2jH"
      },
      "outputs": [],
      "source": [
        "# Comparaison élément par élément des étiquettes augmentées et originales\n",
        "comparison_result = np.equal(augmented_labels, original_labels)\n",
        "\n",
        "# Recherche des valeurs uniques dans le tableau de comparaisons\n",
        "unique_values = np.unique(comparison_result)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4ZUKNoFt5rzZ",
        "outputId": "ef7c17f0-d828-4010-f034-3a3a39f2296a"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(27100, 28, 28, 1)"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ],
      "source": [
        "augmented_data.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WPIlp8pt5uNa",
        "outputId": "b6d65b3b-55d9-454c-d993-3777dcfd160c"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(27100, 28, 28, 1)"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ],
      "source": [
        "original_data.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 465
        },
        "id": "J4mLEfhOPliJ",
        "outputId": "32f2a973-bc78-43bf-e824-10759e3e467f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "9\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7a6754b57820>"
            ]
          },
          "metadata": {},
          "execution_count": 19
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "print(augmented_labels[0])\n",
        "\n",
        "plt.imshow(augmented_data[0, :, :, 0])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 447
        },
        "id": "p9E9qXEo6AW6",
        "outputId": "22f69488-678b-492c-f53c-a3ce2187b632"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7a67528f4070>"
            ]
          },
          "metadata": {},
          "execution_count": 20
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "plt.imshow(original_data[0, :, :, 0])\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Neovg7jzeGyQ"
      },
      "source": [
        "# Baseline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sFn6gBX4Xr7_"
      },
      "outputs": [],
      "source": [
        "# Définition de la forme de l'entrée du modèle, qui est une image de 28x28 pixels\n",
        "inputs = keras.Input(shape=(28, 28), name=\"digits\")\n",
        "\n",
        "# Couche Dense avec 128 neurones et une fonction d'activation ReLU\n",
        "x1 = keras.layers.Dense(128, activation=\"relu\")(inputs)\n",
        "\n",
        "# Couche de sortie Dense avec 10 neurones (un pour chaque classe de chiffre)\n",
        "outputs = keras.layers.Dense(10, name=\"predictions\")(x1)\n",
        "\n",
        "# Création du modèle en spécifiant les entrées et les sorties\n",
        "model = keras.Model(inputs=inputs, outputs=outputs)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a960ShGDbsop"
      },
      "outputs": [],
      "source": [
        "# Création d'un modèle séquentiel en spécifiant les couches dans l'ordre\n",
        "model = keras.Sequential([\n",
        "    # Couche Flatten pour convertir une image 28x28 en un vecteur unidimensionnel de taille 784\n",
        "    tf.keras.layers.Flatten(input_shape=(28, 28)),\n",
        "\n",
        "    # Couche Dense avec 128 neurones et une fonction d'activation ReLU\n",
        "    tf.keras.layers.Dense(128, activation='relu'),\n",
        "\n",
        "    # Couche Dense de sortie avec 10 neurones correspondant aux classes de chiffres\n",
        "    tf.keras.layers.Dense(10, name=\"classifier\")\n",
        "])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eJtguCpGX8JO"
      },
      "outputs": [],
      "source": [
        "# Initialisation de l'optimiseur Adam\n",
        "optimizer = keras.optimizers.Adam()\n",
        "\n",
        "# Initialisation de la fonction de perte SparseCategoricalCrossentropy\n",
        "# from_logits=True indique que les sorties du modèle sont non normalisées (logits)\n",
        "loss_fn = keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
        "\n",
        "# Initialisation de la métrique d'exactitude pour l'entraînement\n",
        "train_acc_metric = keras.metrics.SparseCategoricalAccuracy()\n",
        "\n",
        "# Initialisation de la métrique d'exactitude pour la validation\n",
        "val_acc_metric = keras.metrics.SparseCategoricalAccuracy()\n",
        "\n",
        "# Définition de la taille du lot (batch size) pour l'entraînement\n",
        "batch_size = 128"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WIfpIc2oYgh0"
      },
      "outputs": [],
      "source": [
        "labels_per_batch=10\n",
        "unlabels_per_batch=59\n",
        "all_x = None\n",
        "for i in range(int(100/labels_per_batch)):\n",
        "    # Si c'est la première itération, concaténer les données étiquetées, non étiquetées et augmentées\n",
        "    if all_x is None:\n",
        "        all_x = np.concatenate((x_train_labeled[i*labels_per_batch:i*labels_per_batch+labels_per_batch], x_train_unlabeled[i*unlabels_per_batch : i*unlabels_per_batch+unlabels_per_batch], x_train_augmented[i*unlabels_per_batch: i*unlabels_per_batch+unlabels_per_batch]))\n",
        "    # Pour les itérations suivantes, concaténer les données aux valeurs existantes dans all_x\n",
        "    else:\n",
        "        all_x = np.concatenate((all_x,x_train_labeled[i*labels_per_batch:i*labels_per_batch+labels_per_batch], x_train_unlabeled[i*unlabels_per_batch : i*unlabels_per_batch+unlabels_per_batch], x_train_augmented[i*unlabels_per_batch: i*unlabels_per_batch+unlabels_per_batch]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KY1O4vZ-dVNm",
        "outputId": "f5d94ec7-9635-4694-c720-23e38e579750"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1280, 28, 28, 1)"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ],
      "source": [
        "all_x.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3JpHTH_LcWJd"
      },
      "outputs": [],
      "source": [
        "# Décoration de la fonction avec @tf.function pour la convertir en un graphe TensorFlow\n",
        "@tf.function\n",
        "def test_step(x, y):\n",
        "    # Évaluation des logits du modèle sur les données de test\n",
        "    val_logits = model(x, training=False)\n",
        "\n",
        "    # Mise à jour de la métrique d'exactitude pour les données de test\n",
        "    val_acc_metric.update_state(y, val_logits)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zMBWC3G0ctWM"
      },
      "outputs": [],
      "source": [
        "# Création d'un ensemble de données à partir des données de test et de leurs étiquettes\n",
        "val_dataset = tf.data.Dataset.from_tensor_slices((x_test, y_test))\n",
        "\n",
        "# Division de l'ensemble de données en lots (batch) de taille 64\n",
        "val_dataset = val_dataset.batch(64)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pH8a26LvYI6_",
        "outputId": "70bbb58f-ad8e-4753-9908-1a538e1198c3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Début de l'époque 0\n",
            "Perte d'entraînement (pour un lot) à l'étape 0: 0.0125\n",
            "Échantillons vus jusqu'à présent : 128\n",
            "Exactitude d'entraînement sur l'époque : 1.0000\n",
            "\n",
            "Début de l'époque 1\n",
            "Perte d'entraînement (pour un lot) à l'étape 0: 0.0118\n",
            "Échantillons vus jusqu'à présent : 128\n",
            "Exactitude d'entraînement sur l'époque : 1.0000\n",
            "\n",
            "Début de l'époque 2\n",
            "Perte d'entraînement (pour un lot) à l'étape 0: 0.0111\n",
            "Échantillons vus jusqu'à présent : 128\n",
            "Exactitude d'entraînement sur l'époque : 1.0000\n",
            "\n",
            "Début de l'époque 3\n",
            "Perte d'entraînement (pour un lot) à l'étape 0: 0.0104\n",
            "Échantillons vus jusqu'à présent : 128\n",
            "Exactitude d'entraînement sur l'époque : 1.0000\n",
            "\n",
            "Début de l'époque 4\n",
            "Perte d'entraînement (pour un lot) à l'étape 0: 0.0098\n",
            "Échantillons vus jusqu'à présent : 128\n",
            "Exactitude d'entraînement sur l'époque : 1.0000\n",
            "\n",
            "Début de l'époque 5\n",
            "Perte d'entraînement (pour un lot) à l'étape 0: 0.0093\n",
            "Échantillons vus jusqu'à présent : 128\n",
            "Exactitude d'entraînement sur l'époque : 1.0000\n",
            "\n",
            "Début de l'époque 6\n",
            "Perte d'entraînement (pour un lot) à l'étape 0: 0.0088\n",
            "Échantillons vus jusqu'à présent : 128\n",
            "Exactitude d'entraînement sur l'époque : 1.0000\n",
            "\n",
            "Début de l'époque 7\n",
            "Perte d'entraînement (pour un lot) à l'étape 0: 0.0083\n",
            "Échantillons vus jusqu'à présent : 128\n",
            "Exactitude d'entraînement sur l'époque : 1.0000\n",
            "\n",
            "Début de l'époque 8\n",
            "Perte d'entraînement (pour un lot) à l'étape 0: 0.0079\n",
            "Échantillons vus jusqu'à présent : 128\n",
            "Exactitude d'entraînement sur l'époque : 1.0000\n",
            "\n",
            "Début de l'époque 9\n",
            "Perte d'entraînement (pour un lot) à l'étape 0: 0.0075\n",
            "Échantillons vus jusqu'à présent : 128\n",
            "Exactitude d'entraînement sur l'époque : 1.0000\n"
          ]
        }
      ],
      "source": [
        "import math\n",
        "\n",
        "# Nombre d'époques\n",
        "epochs = 10\n",
        "\n",
        "# Boucle sur les époques\n",
        "for epoch in range(epochs):\n",
        "    print(\"\\nDébut de l'époque %d\" % (epoch,))\n",
        "\n",
        "    # Itérer sur les lots (batches) de l'ensemble de données combiné (all_x)\n",
        "    for step in range(math.ceil(all_x.shape[0] / batch_size)):\n",
        "        # Extraire le lot d'images et d'étiquettes étiquetées\n",
        "        x_batch_train = all_x[step * batch_size:step * batch_size + labels_per_batch]\n",
        "        y_batch_train = y_train_labeled[step * labels_per_batch:step * labels_per_batch + labels_per_batch]\n",
        "\n",
        "        # Ouvrir une GradientTape pour enregistrer les opérations effectuées\n",
        "        # pendant la passe avant, ce qui permet l'autodifférenciation.\n",
        "        with tf.GradientTape() as tape:\n",
        "            # Exécuter la passe avant du modèle sur le lot.\n",
        "            # Les opérations appliquées aux entrées du modèle\n",
        "            # seront enregistrées sur la GradientTape.\n",
        "            logits = model(x_batch_train, training=True)  # Logits pour ce lot\n",
        "            # Calcul de la valeur de perte pour ce lot.\n",
        "            loss_value = loss_fn(y_batch_train, logits[:labels_per_batch])\n",
        "\n",
        "        # Utiliser la bande de gradient pour récupérer automatiquement\n",
        "        # les gradients des variables entraînables par rapport à la perte.\n",
        "        grads = tape.gradient(loss_value, model.trainable_weights)\n",
        "\n",
        "        # Exécuter une étape de descente de gradient en mettant à jour\n",
        "        # la valeur des variables pour minimiser la perte.\n",
        "        optimizer.apply_gradients(zip(grads, model.trainable_weights))\n",
        "\n",
        "        # Mettre à jour la métrique d'entraînement.\n",
        "        train_acc_metric.update_state(y_batch_train, logits[:labels_per_batch])\n",
        "\n",
        "        # Afficher les métriques toutes les 200 lots.\n",
        "        if step % 200 == 0:\n",
        "            print(\n",
        "                \"Perte d'entraînement (pour un lot) à l'étape %d: %.4f\"\n",
        "                % (step, float(loss_value))\n",
        "            )\n",
        "            print(\"Échantillons vus jusqu'à présent : %s\" % ((step + 1) * batch_size))\n",
        "\n",
        "    # Afficher les métriques à la fin de chaque époque.\n",
        "    train_acc = train_acc_metric.result()\n",
        "    print(\"Exactitude d'entraînement sur l'époque : %.4f\" % (float(train_acc),))\n",
        "\n",
        "    # Réinitialiser les métriques d'entraînement à la fin de chaque époque.\n",
        "    train_acc_metric.reset_states()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kUeE13HCcm1c",
        "outputId": "e616f70b-d947-4605-eb8d-e8b9127b0214"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Exactitude de validation : 0.7063\n"
          ]
        }
      ],
      "source": [
        "# Itérer sur les lots de l'ensemble de données de validation\n",
        "for x_batch_val, y_batch_val in val_dataset:\n",
        "    # Exécuter la passe avant du modèle sur le lot de validation.\n",
        "    val_logits = model(x_batch_val, training=False)\n",
        "\n",
        "    # Mettre à jour les métriques de validation\n",
        "    val_acc_metric.update_state(y_batch_val, val_logits)\n",
        "\n",
        "# Calculer et afficher l'exactitude de validation à la fin de l'évaluation\n",
        "val_acc = val_acc_metric.result()\n",
        "val_acc_metric.reset_states()\n",
        "print(\"Exactitude de validation : %.4f\" % (float(val_acc),))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IaztNgM9gBj-"
      },
      "source": [
        "# UDA Implementation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-t_1pH5MgORE"
      },
      "outputs": [],
      "source": [
        "def _kl_divergence_with_logits(p_logits, q_logits):\n",
        "    # Calcul des distributions de probabilités à partir des logits\n",
        "    p = tf.nn.softmax(p_logits)        # Distribution de probabilité pour p\n",
        "    log_p = tf.nn.log_softmax(p_logits) # Logarithme de la softmax de p\n",
        "    log_q = tf.nn.log_softmax(q_logits) # Logarithme de la softmax de q\n",
        "\n",
        "    # Calcul de la divergence de Kullback-Leibler\n",
        "    kl = tf.reduce_sum(p * (log_p - log_q), -1)\n",
        "\n",
        "    return kl"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-5mnovqSa-Vz"
      },
      "outputs": [],
      "source": [
        "def get_ent(logits, return_mean=True):\n",
        "    # Calcul du logarithme de la softmax des logits\n",
        "    log_prob = tf.nn.log_softmax(logits, axis=-1)\n",
        "\n",
        "    # Calcul de la probabilité à partir du logarithme de la softmax\n",
        "    prob = tf.exp(log_prob)\n",
        "\n",
        "    # Calcul de l'entropie\n",
        "    ent = tf.reduce_sum(-prob * log_prob, axis=-1)\n",
        "\n",
        "    # Si return_mean est True, calculer la moyenne de l'entropie\n",
        "    if return_mean:\n",
        "        ent = tf.reduce_mean(ent)\n",
        "\n",
        "    return ent\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RGgYZnz_UsHy"
      },
      "outputs": [],
      "source": [
        "def get_tsa_threshold(schedule, global_step, num_train_steps, start, end):\n",
        "    # Calcul du ratio de l'étape globale par rapport au nombre total d'étapes d'entraînement\n",
        "    step_ratio = float(global_step) / float(num_train_steps)\n",
        "\n",
        "    # Sélection du calendrier (schedule) spécifié\n",
        "    if schedule == \"linear_schedule\":\n",
        "        # Calendrier linéaire\n",
        "        coeff = step_ratio\n",
        "    elif schedule == \"exp_schedule\":\n",
        "        # Calendrier exponentiel avec échelle 5\n",
        "        scale = 5\n",
        "        # [exp(-5), exp(0)] = [1e-2, 1]\n",
        "        coeff = tf.exp((step_ratio - 1) * scale)\n",
        "    elif schedule == \"log_schedule\":\n",
        "        # Calendrier logarithmique avec échelle 5\n",
        "        scale = 5\n",
        "        # [1 - exp(0), 1 - exp(-5)] = [0, 0.99]\n",
        "        coeff = 1 - tf.exp((-step_ratio) * scale)\n",
        "\n",
        "    # Calcul du seuil en fonction du calendrier spécifié\n",
        "    return coeff * (end - start) + start\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3Qgn7O0jUkF5"
      },
      "outputs": [],
      "source": [
        "def anneal_sup_loss(sup_logits, sup_labels, sup_loss, global_step, nbr_steps, num_classes, tsa_schedule):\n",
        "    # Définir le début du seuil TSA en fonction du nombre de classes\n",
        "    tsa_start = 1. / num_classes\n",
        "\n",
        "    # Obtenir le seuil effectif en utilisant la fonction get_tsa_threshold\n",
        "    eff_train_prob_threshold = get_tsa_threshold(\n",
        "        tsa_schedule, global_step, nbr_steps,\n",
        "        tsa_start, end=1)\n",
        "\n",
        "    # Convertir les étiquettes en one-hot encoding\n",
        "    one_hot_labels = tf.one_hot(\n",
        "        sup_labels, depth=num_classes, dtype=tf.float32)\n",
        "\n",
        "    # Calculer les probabilités de softmax pour les logits supervisés\n",
        "    sup_probs = tf.nn.softmax(sup_logits, axis=-1)\n",
        "\n",
        "    # Calculer les probabilités des étiquettes correctes\n",
        "    correct_label_probs = tf.reduce_sum(\n",
        "        one_hot_labels * sup_probs, axis=-1)\n",
        "\n",
        "    # Comparer les probabilités correctes avec le seuil effectif\n",
        "    larger_than_threshold = tf.greater(\n",
        "        correct_label_probs, eff_train_prob_threshold)\n",
        "\n",
        "    # Créer un masque de perte en fonction de la comparaison\n",
        "    loss_mask = 1 - tf.cast(larger_than_threshold, tf.float32)\n",
        "    loss_mask = tf.stop_gradient(loss_mask)\n",
        "\n",
        "    # Appliquer le masque à la perte supervisée\n",
        "    sup_loss = sup_loss * loss_mask\n",
        "\n",
        "    # Calculer la perte supervisée moyenne en tenant compte du masque\n",
        "    avg_sup_loss = (tf.reduce_sum(sup_loss) /\n",
        "                    tf.maximum(tf.reduce_sum(loss_mask), 1))\n",
        "\n",
        "    return sup_loss, avg_sup_loss\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bCYF7QA_qGHu"
      },
      "outputs": [],
      "source": [
        "import keras\n",
        "import copy\n",
        "\n",
        "def create_train(hyper, epochs=10, pretraining=False, verbose=False):\n",
        "\n",
        "    # Copie profonde des hyperparamètres pour éviter les modifications indésirables\n",
        "    hyper = copy.deepcopy(hyper)\n",
        "\n",
        "    # Définition de l'architecture du modèle\n",
        "    model = keras.Sequential([\n",
        "        tf.keras.layers.Flatten(input_shape=(28, 28)),\n",
        "        tf.keras.layers.Dense(256, activation='relu', kernel_regularizer=keras.regularizers.l2(hyper[\"l2\"]),\n",
        "                              # kernel_initializer=keras.initializers.he_normal\n",
        "                             ),\n",
        "        tf.keras.layers.Dropout(hyper[\"dropout\"]),\n",
        "        tf.keras.layers.Dense(128, activation='relu', kernel_regularizer=keras.regularizers.l2(hyper[\"l2\"]),\n",
        "                              # kernel_initializer=keras.initializers.he_normal\n",
        "                             ),\n",
        "        tf.keras.layers.Dropout(hyper[\"dropout\"]),\n",
        "        tf.keras.layers.Dense(10, name=\"classifier\")\n",
        "    ])\n",
        "\n",
        "    # Configuration des hyperparamètres pour l'entraînement\n",
        "    hyper[\"optimizer\"] = keras.optimizers.Adam()\n",
        "    hyper[\"loss_fn\"] = keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
        "    hyper[\"train_acc_metric\"] = keras.metrics.SparseCategoricalAccuracy()\n",
        "    hyper[\"val_acc_metric\"] = keras.metrics.SparseCategoricalAccuracy()\n",
        "\n",
        "    # Création de l'ensemble de données de validation\n",
        "    val_dataset = tf.data.Dataset.from_tensor_slices((x_test, y_test))\n",
        "    val_dataset = val_dataset.batch(128)\n",
        "\n",
        "    # Entraînement préalable si spécifié\n",
        "    if pretraining:\n",
        "        print(\"Démarrage de l'entraînement préalable\")\n",
        "        pretrain(model, x_train_labeled, y_train_labeled, val_dataset, epochs)\n",
        "\n",
        "    # Entraînement principal\n",
        "    print(\"Démarrage de l'entraînement\")\n",
        "    train(model, x_train_labeled, original_data, augmented_data, val_dataset, hyper, epochs, verbose=verbose)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tNSsWB_nqG-s"
      },
      "outputs": [],
      "source": [
        "def pretrain(model, x_train, y_train, val_dataset, epochs=10, verbose=False):\n",
        "    # Configuration de l'optimiseur, de la fonction de perte, et des métriques\n",
        "    model.compile(\n",
        "        optimizer=tf.keras.optimizers.Adam(),\n",
        "        loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "        metrics=[tf.keras.metrics.SparseCategoricalAccuracy()],\n",
        "    )\n",
        "\n",
        "    # Entraînement du modèle sur les données étiquetées\n",
        "    model.fit(\n",
        "        x_train, y_train,\n",
        "        epochs=epochs,\n",
        "        validation_data=val_dataset,\n",
        "        verbose=0  # Utiliser verbose=1 pour afficher des détails d'entraînement pendant les époques\n",
        "    )\n",
        "\n",
        "    # Évaluation et affichage de la précision sur l'ensemble de validation après l'entraînement préalable\n",
        "    val_accuracy = model.evaluate(val_dataset, batch_size=128)[1]\n",
        "    print(\"Précision de validation après l'entraînement préalable: %.4f \\n\\n\" % val_accuracy)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "G8XnFzMxqMXq"
      },
      "outputs": [],
      "source": [
        "def train(model,x_train_labeled,original_data,augmented_data,val_dataset, hyper, epochs=10, verbose=False):\n",
        "\n",
        "    @tf.function\n",
        "    def test_step(x, y):\n",
        "        val_logits = model(x, training=False)\n",
        "        val_acc_metric.update_state(y, val_logits)\n",
        "\n",
        "    unlabels_per_batch = hyper[\"unlabels_per_batch\"]\n",
        "    batch_unique_labels = hyper[\"batch_unique_labels\"]\n",
        "    labels_per_batch = hyper[\"labels_per_batch\"]\n",
        "    hyper[\"labels_per_batch\"]\n",
        "\n",
        "    optimizer = hyper[\"optimizer\"]\n",
        "    loss_fn = hyper[\"loss_fn\"]\n",
        "    train_acc_metric = hyper[\"train_acc_metric\"]\n",
        "    val_acc_metric = hyper[\"val_acc_metric\"]\n",
        "    tsa_schedule = hyper[\"tsa_schedule\"]\n",
        "    num_classes = hyper[\"num_classes\"]\n",
        "    uda_softmax_temp = hyper[\"uda_softmax_temp\"]\n",
        "    uda_confidence_thresh = hyper[\"uda_confidence_thresh\"]\n",
        "    ent_min_coeff = hyper[\"ent_min_coeff\"]\n",
        "    lamd = hyper[\"lamd\"]\n",
        "    # Boucle principale sur les époques\n",
        "    for epoch in trange(epochs):\n",
        "        if(verbose):\n",
        "            print(\"\\nStart of epoch %d\" % (epoch,))\n",
        "        start_time = time.time()\n",
        "\n",
        "        # Itération sur les lots du jeu de données\n",
        "        for step in range(int(original_data.shape[0]/unlabels_per_batch)):\n",
        "            # Séparation des différents types d'images : supervisées, originales non étiquetées, augmentées non étiquetées\n",
        "            sup_images = x_train_labeled[int(step % batch_unique_labels)*labels_per_batch:int(step % batch_unique_labels)*labels_per_batch+labels_per_batch]\n",
        "            ori_images = original_data[step*unlabels_per_batch: step*unlabels_per_batch+unlabels_per_batch]\n",
        "            aug_images = augmented_data[step*unlabels_per_batch: step*unlabels_per_batch+unlabels_per_batch]\n",
        "\n",
        "            # Concaténation pour former le lot d'entraînement\n",
        "            x_batch_train = np.concatenate((sup_images, ori_images, aug_images))\n",
        "            y_batch_train = y_train_labeled[int(step % batch_unique_labels)*labels_per_batch:int(step % batch_unique_labels)*labels_per_batch+labels_per_batch]\n",
        "\n",
        "            # Utilisation de GradientTape pour enregistrer les opérations pendant la passe avant\n",
        "            with tf.GradientTape() as tape:\n",
        "                # Passe avant pour obtenir les logits\n",
        "                logits = model(x_batch_train, training=True)\n",
        "                # Extraction des logits pour les exemples supervisés\n",
        "                sup_logits = logits[:labels_per_batch]\n",
        "                # Calcul de la perte supervisée\n",
        "                sup_loss = loss_fn(y_batch_train, sup_logits)\n",
        "\n",
        "                # Utilisation de la perte TSA si spécifiée\n",
        "                if tsa_schedule:\n",
        "                    sup_loss, avg_sup_loss = anneal_sup_loss(sup_logits, y_batch_train, sup_loss, epoch, epochs, num_classes, tsa_schedule)\n",
        "                else:\n",
        "                    avg_sup_loss = tf.reduce_mean(sup_loss)\n",
        "                total_loss = avg_sup_loss\n",
        "\n",
        "                # Calcul de la perte à partir des données non étiquetées\n",
        "\n",
        "                # Logits des images non étiquetées réelles\n",
        "                ori_logits = logits[labels_per_batch: labels_per_batch + unlabels_per_batch]\n",
        "                # Logits des images non étiquetées augmentées\n",
        "                aug_logits = logits[labels_per_batch + unlabels_per_batch:]\n",
        "\n",
        "                # Ajustement des prédictions avec un softmax tempéré si spécifié\n",
        "                if uda_softmax_temp != -1:\n",
        "                    ori_logits_tgt = ori_logits / uda_softmax_temp\n",
        "                else:\n",
        "                    ori_logits_tgt = ori_logits\n",
        "\n",
        "                # calcul de KL divergence\n",
        "                aug_loss = _kl_divergence_with_logits(\n",
        "                    p_logits=tf.stop_gradient(ori_logits_tgt),\n",
        "                    q_logits=aug_logits)\n",
        "\n",
        "                if uda_confidence_thresh != -1:\n",
        "                    ori_prob = tf.nn.softmax(ori_logits, axis=-1)\n",
        "                    largest_prob = tf.reduce_max(ori_prob, axis=-1)\n",
        "                    loss_mask = tf.cast(tf.greater(\n",
        "                        largest_prob, uda_confidence_thresh), tf.float32)\n",
        "                    loss_mask = tf.stop_gradient(loss_mask)\n",
        "                    aug_loss = aug_loss * loss_mask\n",
        "\n",
        "                if ent_min_coeff > 0:\n",
        "                    per_example_ent = get_ent(ori_logits)\n",
        "                    ent_min_loss = tf.reduce_mean(per_example_ent)\n",
        "                    total_loss = total_loss + ent_min_coeff * ent_min_loss\n",
        "\n",
        "                avg_unsup_loss = tf.reduce_mean(aug_loss)\n",
        "\n",
        "                total_loss += lamd * avg_unsup_loss\n",
        "\n",
        "\n",
        "            # Utilisation de GradientTape pour récupérer automatiquement\n",
        "            # les gradients des variables entraînables par rapport à la perte\n",
        "            grads = tape.gradient(total_loss, model.trainable_weights)\n",
        "\n",
        "            # Exécution d'une étape de descente de gradient en mettant à jour\n",
        "            # les valeurs des variables pour minimiser la perte\n",
        "            optimizer.apply_gradients(zip(grads, model.trainable_weights))\n",
        "\n",
        "            # Mise à jour de la métrique d'entraînement\n",
        "            train_acc_metric.update_state(y_batch_train, logits[:labels_per_batch])\n",
        "\n",
        "            if verbose:\n",
        "                if step % 50 == 0:\n",
        "                    print(\n",
        "                        \"Training loss (for one batch) at step %d: %.4f\"\n",
        "                        % (step, float(total_loss))\n",
        "                    )\n",
        "                    print(\"Seen so far: %s samples\" % ((step + 1) * batch_size))\n",
        "\n",
        "        # Affichages des métriques à chaque fin d'itération\n",
        "        train_acc = train_acc_metric.result()\n",
        "        print(\"Training acc over epoch: %.4f\" % (float(train_acc),))\n",
        "\n",
        "        train_acc_metric.reset_states()\n",
        "\n",
        "        for x_batch_val, y_batch_val in val_dataset:\n",
        "            test_step(x_batch_val, y_batch_val)\n",
        "\n",
        "        val_acc = val_acc_metric.result()\n",
        "        val_acc_metric.reset_states()\n",
        "        print(\"Validation acc: %.4f\" % (float(val_acc),))\n",
        "        if verbose:\n",
        "            print(\"Time taken: %.2fs \\n\" % (time.time() - start_time))\n",
        "    return float(val_acc)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WlWKPDuT1yr4"
      },
      "outputs": [],
      "source": [
        "val_dataset = tf.data.Dataset.from_tensor_slices((x_test, y_test))\n",
        "val_dataset = val_dataset.batch(128)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zZVTyyvYqPVu"
      },
      "outputs": [],
      "source": [
        "labels_per_batch = 50\n",
        "batch_size = 128\n",
        "\n",
        "hyper = {\n",
        "    \"labels_per_batch\":labels_per_batch,\n",
        "    \"batch_size\" : batch_size,\n",
        "    \"batch_unique_labels\":100/labels_per_batch,\n",
        "    \"unlabels_per_batch\":int((batch_size-labels_per_batch)/2),\n",
        "    \"nbr_batch\" : 100,\n",
        "    \"lamd\" : 1,\n",
        "    \"tsa_schedule\":\"exp_schedule\",\n",
        "    # tsa_schedule=\"\"\n",
        "    \"num_classes\" : 10,\n",
        "    \"uda_softmax_temp\" : 0.9,\n",
        "    \"uda_confidence_thresh\" : 0.8,\n",
        "    \"ent_min_coeff\" : 0.5,\n",
        "\n",
        "    \"num_classes\" : 10,\n",
        "    \"decay_steps\" : 1000,\n",
        "    \"moving_average_decay\":0.9999,\n",
        "    \"initial_learning_rate\":1e-2,\n",
        "    \"dropout\":0.8,\n",
        "    \"l2\": 0.1\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tHYqopfXqQie",
        "outputId": "2147457c-950c-4420-db2f-fefe7b557e82"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Démarrage de l'entraînement\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/10 [00:00<?, ?it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training acc over epoch: 0.6930\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 10%|█         | 1/10 [00:35<05:15, 35.06s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation acc: 0.7486\n",
            "Training acc over epoch: 0.9131\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 20%|██        | 2/10 [01:08<04:33, 34.24s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation acc: 0.7794\n",
            "Training acc over epoch: 0.9338\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 30%|███       | 3/10 [01:43<04:01, 34.51s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation acc: 0.7877\n",
            "Training acc over epoch: 0.9454\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 40%|████      | 4/10 [02:18<03:28, 34.70s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation acc: 0.7878\n",
            "Training acc over epoch: 0.9498\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 50%|█████     | 5/10 [02:53<02:53, 34.74s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation acc: 0.8111\n",
            "Training acc over epoch: 0.9567\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 60%|██████    | 6/10 [03:28<02:19, 34.93s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation acc: 0.8339\n",
            "Training acc over epoch: 0.9625\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 70%|███████   | 7/10 [04:03<01:44, 34.77s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation acc: 0.8321\n",
            "Training acc over epoch: 0.9661\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 80%|████████  | 8/10 [04:37<01:09, 34.60s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation acc: 0.8339\n",
            "Training acc over epoch: 0.9716\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 90%|█████████ | 9/10 [05:11<00:34, 34.31s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation acc: 0.8411\n",
            "Training acc over epoch: 0.9728\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 10/10 [05:45<00:00, 34.59s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation acc: 0.8404\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "create_train(hyper, epochs=10, pretraining=False, verbose=False)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "N0n-M1Xpd-fl",
        "yO8OPXjJgFE3"
      ],
      "provenance": []
    },
    "kernelspec": {
      "display_name": "default:Python",
      "language": "python",
      "name": "conda-env-default-py"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}